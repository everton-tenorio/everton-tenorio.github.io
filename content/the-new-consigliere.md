---
title: "The New Consigliere"
date: 2025-07-03
slug: the-new-consigliere
description: ""
tags: ["ChatGPT", "LLMs", "AI ethics", "decision making", "AI and therapy", "psychological impact AI"]
bannerImage: "https://i.ibb.co/RkH3dZpF/consigliere.jpg"
---

Once, Machiavelli warned that a prudent ruler should avoid flatterers as much as possible, for they distort reality and feed dangerous illusions. Instead, he recommended that the prince allow only a few chosen people to speak frankly, and even then, only when asked. The final decision should always rest with the prince, based on his own judgment.

Fast forward to 2025, and the difference now is that we, the citizens, are the ones who must master the art of wisely listening to a few. We are the princes of our own time. Power no longer resides solely in palaces, it also belongs to those with access to information, interpretation, and rapid communication. Yet the consigliere of the past seem to have changed, becoming more like influencers or alienators.

"Young people no longer make life decisions without asking ChatGPT", says Sam Altman, noting that a particular age group of university students is using ChatGPT as a daily operating system for everything. This trend has triggered studies into the potential benefits and harms of such use. LLMs are essentially deep learning systems that continuously evolve. So when it comes to practical matters. business decisions, medical questions, planning, they often respond coherently. But in more complex areas, where people use them as substitutes for psychotherapy, the results may be far less reliable.

The Harvard Business Review, published by the graduate business school at Harvard University, released a report last month showing that therapeutic counseling has become the main reason people are using AI tools this year. Three other personal uses also rank in the top ten: organizing personal life, finding a sense of purpose, and achieving a healthier lifestyle. Right now, somewhere, someone in crisis is asking an LLM what they should do.

There are experts who believe that with technological advances, these tools could indeed become more effective in such areas, making it much easier to follow Machiavelli’s advice. However, just as there were warnings in the past, it’s important to raise flags now: ethical concerns, data training flaws, reliability, and even security issues, since exploiting vulnerabilities in LLMs can lead them to say exactly what they shouldn’t. And that’s already happening.

But when used appropriately and with critical thinking, fully aware of the potential for alienation, the responsibility still lies with you, the ruler, to draw your own conclusions.
